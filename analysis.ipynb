{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import input_file_name, substring_index, to_timestamp, year, month, dayofweek, weekofyear, date_format, lit\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "spark = SparkSession.builder.config(\"spark.jars\", \"./drivers/postgresql-42.2.18.jar\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('./data/nyse-listed_json.json')\n",
    "df2 = spark.read.json('./data/other-listed_json.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------------------+--------+\n|ACT Symbol|        Company Name|Exchange|\n+----------+--------------------+--------+\n|         A|Agilent Technolog...|       N|\n|        AA|Alcoa Inc. Common...|       N|\n|      AA$B|Alcoa Inc. Deposi...|       N|\n|       AAC|AAC Holdings, Inc...|       N|\n|       AAN|Aaron's, Inc. Com...|       N|\n|       AAP|Advance Auto Part...|       N|\n|       AAT|American Assets T...|       N|\n|       AAV|Advantage Oil & G...|       N|\n|        AB|Allianceberstein ...|       N|\n|       ABB|ABB Ltd Common Stock|       N|\n|      ABBV|AbbVie Inc. Commo...|       N|\n|       ABC|AmerisourceBergen...|       N|\n|      ABEV|Ambev S.A. Americ...|       N|\n|       ABG|Asbury Automotive...|       N|\n|       ABM|ABM Industries In...|       N|\n|       ABR|Arbor Realty Trus...|       N|\n|     ABR$A|Arbor Realty Trus...|       N|\n|     ABR$B|Arbor Realty Trus...|       N|\n|     ABR$C|Arbor Realty Trus...|       N|\n|      ABRN|Arbor Realty Trus...|       N|\n+----------+--------------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('Exchange', lit('N'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+--------------------+---+--------+-------------+--------------+--------------------+----------+\n|ACT Symbol|CQS Symbol|        Company Name|ETF|Exchange|NASDAQ Symbol|Round Lot Size|       Security Name|Test Issue|\n+----------+----------+--------------------+---+--------+-------------+--------------+--------------------+----------+\n|         A|         A|Agilent Technolog...|  N|       N|            A|         100.0|Agilent Technolog...|         N|\n|        AA|        AA|Alcoa Inc. Common...|  N|       N|           AA|         100.0|Alcoa Inc. Common...|         N|\n|       AA$|       AAp|Alcoa Inc. $3.75 ...|  N|       A|          AA-|         100.0|Alcoa Inc. $3.75 ...|         N|\n|      AA$B|      AApB|Alcoa Inc. Deposi...|  N|       N|         AA-B|         100.0|Alcoa Inc. Deposi...|         N|\n|       AAC|       AAC|AAC Holdings, Inc...|  N|       N|          AAC|         100.0|AAC Holdings, Inc...|         N|\n|      AADR|      AADR|WCM BNY Mellon Fo...|  Y|       P|         AADR|         100.0|WCM BNY Mellon Fo...|         N|\n|      AAMC|      AAMC|Altisource Asset ...|  N|       A|         AAMC|         100.0|Altisource Asset ...|         N|\n|       AAN|       AAN|Aaron's, Inc. Com...|  N|       N|          AAN|         100.0|Aaron's, Inc. Com...|         N|\n|       AAP|       AAP|Advance Auto Part...|  N|       N|          AAP|         100.0|Advance Auto Part...|         N|\n|       AAT|       AAT|American Assets T...|  N|       N|          AAT|         100.0|American Assets T...|         N|\n|       AAU|       AAU|Almaden Minerals,...|  N|       A|          AAU|         100.0|Almaden Minerals,...|         N|\n|       AAV|       AAV|Advantage Oil & G...|  N|       N|          AAV|         100.0|Advantage Oil & G...|         N|\n|        AB|        AB|Allianceberstein ...|  N|       N|           AB|         100.0|Allianceberstein ...|         N|\n|       ABB|       ABB|ABB Ltd Common Stock|  N|       N|          ABB|         100.0|ABB Ltd Common Stock|         N|\n|      ABBV|      ABBV|AbbVie Inc. Commo...|  N|       N|         ABBV|         100.0|AbbVie Inc. Commo...|         N|\n|       ABC|       ABC|AmerisourceBergen...|  N|       N|          ABC|         100.0|AmerisourceBergen...|         N|\n|      ABEV|      ABEV|Ambev S.A. Americ...|  N|       N|         ABEV|         100.0|Ambev S.A. Americ...|         N|\n|       ABG|       ABG|Asbury Automotive...|  N|       N|          ABG|         100.0|Asbury Automotive...|         N|\n|       ABM|       ABM|ABM Industries In...|  N|       N|          ABM|         100.0|ABM Industries In...|         N|\n|       ABR|       ABR|Arbor Realty Trus...|  N|       N|          ABR|         100.0|Arbor Realty Trus...|         N|\n+----------+----------+--------------------+---+--------+-------------+--------------+--------------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------+------+------+--------+----------+-------------------+---------+\n|Open  |High  |Low   |Close |Volume  |act_symbol|date_formatted     |full_date|\n+------+------+------+------+--------+----------+-------------------+---------+\n|45.722|45.75 |44.967|45.665|11700414|qqq       |1999-03-10 00:00:00|19990310 |\n|45.994|46.26 |44.988|45.88 |21670048|qqq       |1999-03-11 00:00:00|19990311 |\n|45.721|45.749|44.406|44.77 |19553768|qqq       |1999-03-12 00:00:00|19990312 |\n|45.101|46.103|44.625|46.052|14245348|qqq       |1999-03-15 00:00:00|19990315 |\n|46.253|46.643|45.749|46.447|10971066|qqq       |1999-03-16 00:00:00|19990316 |\n|46.443|46.5  |45.969|46.106|8867842 |qqq       |1999-03-17 00:00:00|19990317 |\n|46.055|47.033|46.042|47.003|10843416|qqq       |1999-03-18 00:00:00|19990318 |\n|47.623|47.623|45.775|45.806|16013553|qqq       |1999-03-19 00:00:00|19990319 |\n|45.992|46.102|45.156|45.24 |11239060|qqq       |1999-03-22 00:00:00|19990322 |\n|44.991|45.16 |43.567|43.65 |24517597|qqq       |1999-03-23 00:00:00|19990323 |\n+------+------+------+------+--------+----------+-------------------+---------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.csv('./data/ETFs/*.txt', sep=',', header=True).withColumn(\"filename\", input_file_name())\n",
    "df3 = df3.withColumn(\"act_symbol\", substring_index(substring_index(df3.filename, \"/\", -1), \".\", 1)) \\\n",
    "    .withColumn('date_formatted', to_timestamp(df3.Date, 'yyyy-MM-dd')) \\\n",
    "    .withColumn('full_date', date_format(df3.Date, \"yyyyMMdd\").cast(IntegerType()))\n",
    "\n",
    "df3 = df3.drop(\"filename\", \"OpenInt\", \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------+------+------+-------+----------+-------------------+---------+\n|Open  |High  |Low   |Close |Volume |act_symbol|date_formatted     |full_date|\n+------+------+------+------+-------+----------+-------------------+---------+\n|0.6277|0.6362|0.6201|0.6201|2575579|ge        |1962-01-02 00:00:00|19620102 |\n|0.6201|0.6201|0.6122|0.6201|1764749|ge        |1962-01-03 00:00:00|19620103 |\n|0.6201|0.6201|0.6037|0.6122|2194010|ge        |1962-01-04 00:00:00|19620104 |\n|0.6122|0.6122|0.5798|0.5957|3255244|ge        |1962-01-05 00:00:00|19620105 |\n|0.5957|0.5957|0.5716|0.5957|3696430|ge        |1962-01-08 00:00:00|19620108 |\n|0.5957|0.6037|0.5878|0.5957|2778285|ge        |1962-01-09 00:00:00|19620109 |\n|0.5957|0.6037|0.5957|0.5957|2337096|ge        |1962-01-10 00:00:00|19620110 |\n|0.5957|0.5957|0.5878|0.5957|1943605|ge        |1962-01-11 00:00:00|19620111 |\n|0.5957|0.6037|0.5878|0.5878|2015151|ge        |1962-01-12 00:00:00|19620112 |\n|0.5957|0.5957|0.5957|0.5957|2527879|ge        |1962-01-15 00:00:00|19620115 |\n+------+------+------+------+-------+----------+-------------------+---------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.read.csv('./data/Stocks/*.txt', sep=',', header=True).withColumn(\"filename\", input_file_name())\n",
    "df4 = df4.withColumn(\"act_symbol\", substring_index(substring_index(df4.filename, \"/\", -1), \".\", 1)) \\\n",
    "    .withColumn('date_formatted', to_timestamp(df4.Date, 'yyyy-MM-dd')) \\\n",
    "    .withColumn('full_date', date_format(df4.Date, \"yyyyMMdd\").cast(IntegerType())) \n",
    "        \n",
    "df4 = df4.drop(\"filename\", \"OpenInt\", \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datedf = df4.select(\"date_formatted\", \"full_date\").distinct() \\\n",
    "    .withColumn(\"day_of_week\", dayofweek(\"date_formatted\")) \\\n",
    "    .withColumn(\"week_of_year\", weekofyear(\"date_formatted\")) \\\n",
    "    .withColumn(\"month\", month(\"date_formatted\")) \\\n",
    "    .withColumn(\"year\", year(\"date_formatted\")) \\\n",
    "    .drop(\"date_formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(df: DataFrame, table_name: str):\n",
    "    user = \"postgres\"\n",
    "    password = \"25March1994\"\n",
    "    url = \"jdbc:postgresql://localhost:5432/capstone\"\n",
    "    properties = {\n",
    "        \"user\": user,\n",
    "        \"password\": password\n",
    "    }\n",
    "    df.write.jdbc(url=url, table=table_name, mode=\"overwrite\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(datedf, \"trade_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_daily_df = df3.unionByName(df4).dropDuplicates()\n",
    "stock_daily_df = stock_daily_df \\\n",
    "    .withColumnRenamed(\"Open\", \"open\") \\\n",
    "    .withColumnRenamed(\"High\", \"high\") \\\n",
    "    .withColumnRenamed(\"Low\", \"low\") \\\n",
    "    .withColumnRenamed(\"Close\", \"close\") \\\n",
    "    .withColumnRenamed(\"Volume\", \"volume\") \\\n",
    "    .drop(\"date_formatted\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- open: double (nullable = true)\n |-- high: double (nullable = true)\n |-- low: double (nullable = true)\n |-- close: double (nullable = true)\n |-- volume: integer (nullable = true)\n |-- act_symbol: string (nullable = false)\n |-- full_date: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "stock_daily_df = stock_daily_df \\\n",
    "    .withColumn(\"open\", stock_daily_df.open.cast(DoubleType())) \\\n",
    "    .withColumn(\"high\", stock_daily_df.high.cast(DoubleType())) \\\n",
    "    .withColumn(\"low\", stock_daily_df.low.cast(DoubleType())) \\\n",
    "    .withColumn(\"close\", stock_daily_df.close.cast(DoubleType())) \\\n",
    "    .withColumn(\"volume\", stock_daily_df.volume.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(stock_daily_df, \"daily_stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = df.union(df2.select(\"ACT Symbol\", \"Company Name\", \"Exchange\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = company_df.dropDuplicates() \\\n",
    "    .withColumnRenamed(\"ACT Symbol\", \"act_symbol\") \\\n",
    "    .withColumnRenamed(\"Company Name\", \"company_name\") \\\n",
    "    .withColumnRenamed(\"Exchange\", \"exchange_code\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(company_df, \"company_details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "exhange_df = spark.read.json('./data/exchange_list.json')\n",
    "country_df = spark.read.json('./data/country_list.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(exhange_df, \"exchange_details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(country_df, \"country_details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(table_name: str, spark: SparkSession):\n",
    "    user = \"postgres\"\n",
    "    password = \"25March1994\"\n",
    "    url = \"jdbc:postgresql://localhost:5432/capstone\"\n",
    "    properties = {\n",
    "        \"user\": user,\n",
    "        \"password\": password\n",
    "    }\n",
    "    df = spark.read.jdbc(url=url, table=table_name, properties=properties)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_table(\"company_details\", spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}